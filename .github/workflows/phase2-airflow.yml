name: phase2-airflow

on:
  push:
    branches: [ main ]
    paths:
      - 'services/airflow/**'
      - '.github/workflows/phase2-airflow.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'services/airflow/**'
  workflow_dispatch:

permissions:
  contents: read

env:
  # Optional; we’ll fall back to eu-west-1 if the repo variable is unset.
  AWS_REGION: ${{ vars.AWS_REGION }}
  # ECR repository name created by Terraform (module output showed “aiml-airflow-image”)
  ECR_REPO: aiml-airflow-image

jobs:
  bandit:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install bandit
      - name: Bandit scan
        working-directory: services/airflow
        run: bandit -r dags -f txt -o bandit-report.txt || true
      - uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: bandit-report
          path: services/airflow/bandit-report.txt

  build_and_push:
    runs-on: ubuntu-latest
    outputs:
      image_repo: ${{ steps.compute.outputs.image_repo }}
      image_ref:  ${{ steps.build.outputs.image_ref }}
    steps:
      - uses: actions/checkout@v4

      - name: Resolve region (fallback)
        run: |
          REGION="${AWS_REGION:-}"
          if [ -z "$REGION" ]; then REGION="eu-west-1"; fi
          echo "REGION=$REGION" >> "$GITHUB_ENV"

      - name: Preflight — check required secrets
        run: |
          [ -n "${{ secrets.AWS_ACCESS_KEY_ID }}" ]     || { echo "::error::Missing repo secret AWS_ACCESS_KEY_ID"; exit 1; }
          [ -n "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ] || { echo "::error::Missing repo secret AWS_SECRET_ACCESS_KEY"; exit 1; }

      - name: Configure AWS creds (static)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.REGION }}

      - name: Compute image repo URI
        id: compute
        run: |
          ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
          echo "image_repo=$ACCOUNT.dkr.ecr.${REGION}.amazonaws.com/${ECR_REPO}" >> "$GITHUB_OUTPUT"

      - uses: aws-actions/amazon-ecr-login@v2

      - name: Build & Push (SHA tag only; no :latest because repo is immutable)
        id: build
        working-directory: services/airflow
        env:
          IMAGE_REPO: ${{ steps.compute.outputs.image_repo }}
        run: |
          set -euo pipefail
          GIT_SHA=$(git rev-parse --short HEAD)
          IMAGE_REF="${IMAGE_REPO}:${GIT_SHA}"

          docker build -t "$IMAGE_REF" .
          docker push  "$IMAGE_REF"

          echo "image_ref=$IMAGE_REF" >> "$GITHUB_OUTPUT"

  deploy:
    runs-on: ubuntu-latest
    needs: build_and_push
    steps:
      - name: Configure AWS creds (static)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region:            ${{ env.AWS_REGION != '' && env.AWS_REGION || 'eu-west-1' }}

      - name: Restart Airflow on EC2 via SSM
        env:
          INSTANCE_ID:      ${{ vars.EC2_INSTANCE_ID }}
          REGION:           ${{ env.AWS_REGION != '' && env.AWS_REGION || 'eu-west-1' }}
          IMAGE_REF:        ${{ needs.build_and_push.outputs.image_ref }}
          RAW_BUCKET:       ${{ vars.RAW_BUCKET }}
          PROCESSED_BUCKET: ${{ vars.PROCESSED_BUCKET }}
          S3_INPUT_PREFIX:  ${{ vars.S3_INPUT_PREFIX }}
          S3_OUTPUT_PREFIX: ${{ vars.S3_OUTPUT_PREFIX }}
        run: |
          set -euo pipefail

          # Build a clean JSON payload (each command is a single line; no trailing backslashes).
          cat > payload.json <<'JSON'
          {
            "commands": [
              "set -euxo pipefail",
              "REGION=__REGION__",
              "IMAGE_REF=__IMAGE_REF__",
              "RAW_BUCKET=__RAW__",
              "PROCESSED_BUCKET=__PROC__",
              "S3_INPUT_PREFIX=__INP__",
              "S3_OUTPUT_PREFIX=__OUT__",
              "ECR_REG=$(echo \"$IMAGE_REF\" | awk -F\"/\" '{print $1}')",
              "command -v docker || (apt-get update -y && apt-get install -y docker.io || yum install -y docker)",
              "systemctl enable --now docker || true",
              "aws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $ECR_REG",
              "docker rm -f airflow || true",
              "docker volume create airflow_home || true",
              "docker volume create airflow_logs || true",
              "docker pull ${IMAGE_REF}",
              "docker run -d --name airflow -p 8080:8080 -e AIRFLOW_ADMIN_USER=admin -e AIRFLOW_ADMIN_PWD=$(aws ssm get-parameter --with-decryption --name /airflow/admin_pwd --region $REGION --query Parameter.Value --output text) -e AIRFLOW_ADMIN_EMAIL=admin@example.com -e AIRFLOW__CORE__LOAD_EXAMPLES=False -e RAW_BUCKET=$RAW_BUCKET -e PROCESSED_BUCKET=$PROCESSED_BUCKET -e S3_INPUT_PREFIX=$S3_INPUT_PREFIX -e S3_OUTPUT_PREFIX=$S3_OUTPUT_PREFIX -e HF_MODEL_PATH=/opt/models/sshleifer/distilbart-cnn-12-6 -v airflow_home:/opt/airflow -v airflow_logs:/opt/airflow/logs ${IMAGE_REF}",
              "docker ps",
              "docker logs --tail 120 airflow || true"
            ]
          }
          JSON

          # Substitute placeholders (safe; avoids JSON escaping headaches).
          sed -i "s|__REGION__|${REGION}|g"            payload.json
          sed -i "s|__IMAGE_REF__|${IMAGE_REF}|g"      payload.json
          sed -i "s|__RAW__|${RAW_BUCKET}|g"           payload.json
          sed -i "s|__PROC__|${PROCESSED_BUCKET}|g"    payload.json
          sed -i "s|__INP__|${S3_INPUT_PREFIX}|g"      payload.json
          sed -i "s|__OUT__|${S3_OUTPUT_PREFIX}|g"     payload.json

          # Send to the instance
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Phase2 Airflow rollout" \
            --parameters file://payload.json \
            --region "$REGION" \
            --output text
