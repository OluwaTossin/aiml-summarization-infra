name: phase2-airflow

on:
  push:
    branches: [ main ]
    paths:
      - 'services/airflow/**'
      - '.github/workflows/phase2-airflow.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'services/airflow/**'
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

# Repo variables are still supported for the DAG inputs, but are now optional
env:
  # Optional; if empty we default to eu-west-1 inside the job
  AWS_REGION: ${{ vars.AWS_REGION }}
  # The image repo name we push to (created by Terraform)
  ECR_REPO: aiml-airflow-image

jobs:
  bandit:
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install bandit
      - name: Bandit scan
        working-directory: services/airflow
        run: bandit -r dags -f txt -o bandit-report.txt || true
      - uses: actions/upload-artifact@v4
        if: ${{ always() }}
        with:
          name: bandit-report
          path: services/airflow/bandit-report.txt

  build_and_push:
    runs-on: ubuntu-latest
    needs: bandit
    if: ${{ always() }}
    outputs:
      image_uri: ${{ steps.build.outputs.image_uri }}
    steps:
      - uses: actions/checkout@v4

      - name: Resolve region (fallback to eu-west-1)
        id: region
        run: |
          REGION="${AWS_REGION:-}"
          if [ -z "$REGION" ]; then REGION="eu-west-1"; fi
          echo "Resolved AWS region: $REGION"
          echo "REGION=$REGION" >> $GITHUB_ENV

      - name: Debug OIDC claims (optional)
        run: |
          sudo apt-get update -y && sudo apt-get install -y jq
          TOK=$(curl -sS -H "Authorization: Bearer $ACTIONS_ID_TOKEN_REQUEST_TOKEN" \
               "${ACTIONS_ID_TOKEN_REQUEST_URL}&audience=sts.amazonaws.com" | jq -r .value)
          echo "OIDC sub:"; echo "$TOK" | awk -F. '{print $2}' | base64 -d 2>/dev/null | jq -r .sub

      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT_ID && vars.AWS_ACCOUNT_ID || '000000000000' }}:role/GitHubOIDCRole
          # The action requires a region even just to get the OIDC creds;
          # use the env we resolved above
          aws-region: ${{ env.REGION }}

      # Discover the real account ID after assuming the role
      - name: Discover AWS account & compute IMAGE_URI
        id: compute
        run: |
          set -euo pipefail
          ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT=$ACCOUNT"
          IMAGE_URI="$ACCOUNT.dkr.ecr.${REGION}.amazonaws.com/${ECR_REPO}"
          echo "IMAGE_URI=$IMAGE_URI"
          echo "IMAGE_URI=$IMAGE_URI" >> $GITHUB_ENV

      - uses: aws-actions/amazon-ecr-login@v2

      - name: Build & Push
        id: build
        working-directory: services/airflow
        run: |
          set -euo pipefail
          GIT_SHA=$(git rev-parse --short HEAD)
          docker build -t "$IMAGE_URI:$GIT_SHA" -t "$IMAGE_URI:latest" .
          docker push "$IMAGE_URI:$GIT_SHA"
          docker push "$IMAGE_URI:latest"
          echo "image_uri=$IMAGE_URI" >> "$GITHUB_OUTPUT"

  deploy:
    runs-on: ubuntu-latest
    needs: build_and_push
    if: ${{ always() }}
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          # Reuse the same region resolution rule
          aws-region: ${{ env.AWS_REGION != '' && env.AWS_REGION || 'eu-west-1' }}
          role-to-assume: arn:aws:iam::${{ vars.AWS_ACCOUNT_ID && vars.AWS_ACCOUNT_ID || '000000000000' }}:role/GitHubOIDCRole

      - name: Restart Airflow on EC2 via SSM
        env:
          INSTANCE_ID: ${{ vars.EC2_INSTANCE_ID }}
          # use the image uri produced by the build job
          IMAGE_URI: ${{ needs.build_and_push.outputs.image_uri }}
          REGION: ${{ env.AWS_REGION != '' && env.AWS_REGION || 'eu-west-1' }}
        run: |
          aws ssm send-command \
            --instance-ids "$INSTANCE_ID" \
            --document-name "AWS-RunShellScript" \
            --comment "Phase2 Airflow rollout" \
            --parameters commands='[
              "set -euxo pipefail",
              "REGION='\''${REGION}'\'''",
              "IMAGE_URI='\''${IMAGE_URI}'\'''",
              # Derive ECR registry from IMAGE_URI to avoid any hard-coded account/region
              "ECR_REG=$(echo \"${IMAGE_URI}\" | awk -F\"/\" '\''{print $1}'\'')",
              "command -v docker || (apt-get update -y && apt-get install -y docker.io || yum install -y docker)",
              "systemctl enable --now docker || true",
              "aws ecr get-login-password --region $REGION | docker login --username AWS --password-stdin $ECR_REG",
              "docker pull '${IMAGE_URI}':latest",
              "docker rm -f airflow || true",
              "docker volume create airflow_home || true",
              "docker volume create airflow_logs || true",
              "docker run -d --name airflow -p 8080:8080 \
                 -e AIRFLOW_ADMIN_USER=admin \
                 -e AIRFLOW_ADMIN_PWD=$(aws ssm get-parameter --with-decryption --name /airflow/admin_pwd --region $REGION --query Parameter.Value --output text) \
                 -e AIRFLOW_ADMIN_EMAIL=admin@example.com \
                 -e AIRFLOW__CORE__LOAD_EXAMPLES=False \
                 -e RAW_BUCKET=${{ vars.RAW_BUCKET }} \
                 -e PROCESSED_BUCKET=${{ vars.PROCESSED_BUCKET }} \
                 -e S3_INPUT_PREFIX=${{ vars.S3_INPUT_PREFIX }} \
                 -e S3_OUTPUT_PREFIX=${{ vars.S3_OUTPUT_PREFIX }} \
                 -e HF_MODEL_PATH=/opt/models/sshleifer/distilbart-cnn-12-6 \
                 -v airflow_home:/opt/airflow \
                 -v airflow_logs:/opt/airflow/logs \
                 '${IMAGE_URI}':latest",
              "docker ps",
              "docker logs --tail 120 airflow || true"
            ]' \
            --region "${{ env.AWS_REGION != '' && env.AWS_REGION || 'eu-west-1' }}"
